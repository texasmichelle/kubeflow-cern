{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TrackML Kubeflow Pipeline\n",
    "\n",
    "This notebook assumes that you have already set up a GKE cluster with Kubeflow installed. Currently, this notebook must be run from the Kubeflow JupyterHub installation.\n",
    "\n",
    "In this notebook, we will show how to:\n",
    "\n",
    "* Interactively define a Kubeflow Pipeline using the Pipelines Python SDK\n",
    "* Submit and run the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some imports and set some variables.  Set the `WORKING_DIR` to a path under the Cloud Storage bucket you created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kfp  # the Pipelines SDK.  This library is included with the notebook image.\n",
    "from kfp import compiler\n",
    "import kfp.dsl as dsl\n",
    "import kfp.gcp as gcp\n",
    "import kfp.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KUBECTL_IMAGE = \"gcr.io/mcas-195423/trackml_master_kfp_kubectl\"\n",
    "KUBECTL_IMAGE_VERSION = \"1\"\n",
    "TRACKML_TRAIN_IMAGE = \"gcr.io/mcas-195423/trackml_master_trackml\"\n",
    "TRACKML_TRAIN_VERSION = \"1\"\n",
    "TRACKML_RESULTSGEN_IMAGE = \"gcr.io/mcas-195423/trackml_master_trackml\"\n",
    "TRACKML_RESULTSGEN_VERSION = \"1\"\n",
    "TRACKML_SCORE_IMAGE = \"gcr.io/mcas-195423/trackml_master_trackml\"\n",
    "TRACKML_SCORE_VERSION = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an *Experiment* in the Kubeflow Pipeline System\n",
    "\n",
    "The Kubeflow Pipeline system requires an \"Experiment\" to group pipeline runs. You can create a new experiment, or call `client.list_experiments()` to get existing ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that this notebook should be running in JupyterHub in the same cluster as the pipeline system.\n",
    "# Otherwise, additional config would be required to connect.\n",
    "client = kfp.Client()\n",
    "client.list_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = client.create_experiment(name='trackml_notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Pipeline\n",
    "\n",
    "Authoring a pipeline is like authoring a normal Python function. The pipeline function describes the topology of the pipeline. \n",
    "\n",
    "Each step in the pipeline is typically a `ContainerOp` --- a simple class or function describing how to interact with a docker container image. In the pipeline, all the container images referenced in the pipeline are already built. \n",
    "\n",
    "The pipeline starts by training a model. When it finishes, it exports the model in a form suitable for serving by [TensorFlow serving](https://github.com/tensorflow/serving/).\n",
    "\n",
    "The next step deploys a TF-serving instance with that model.\n",
    "\n",
    "The last step generates a results file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_op():\n",
    "  return dsl.ContainerOp(\n",
    "    name='train',\n",
    "    image=\"{}:{}\".format(TRACKML_TRAIN_IMAGE, TRACKML_TRAIN_VERSION),\n",
    "    command=[\"python\"],\n",
    "    arguments=[\"train.py\"],\n",
    "  ).apply(gcp.use_gcp_secret()\n",
    "  )#.set_gpu_limit(1)\n",
    "\n",
    "def serve_op():\n",
    "  return dsl.ContainerOp(\n",
    "    name='serve',\n",
    "    image=\"{}:{}\".format(KUBECTL_IMAGE, KUBECTL_IMAGE_VERSION),\n",
    "    arguments=[\n",
    "      \"/src/set_kubectl.sh\",\n",
    "      \"--namespace\", \"kubeflow\",\n",
    "      \"--command\", \"apply -f /src/k8s/serve.yaml\",\n",
    "    ]\n",
    "  ).apply(gcp.use_gcp_secret())\n",
    "\n",
    "def resultsgen_op():\n",
    "  return dsl.ContainerOp(\n",
    "    name='resultsgen',\n",
    "    image=\"{}:{}\".format(TRACKML_RESULTSGEN_IMAGE, TRACKML_RESULTSGEN_VERSION),\n",
    "    command=[\"python\"],\n",
    "    arguments=[\"resultsgen.py\"],\n",
    "  ).apply(gcp.use_gcp_secret())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "  name='trackml',\n",
    "  description='A pipeline that predicts particle tracks'\n",
    ")\n",
    "def trackml():\n",
    "  train = train_op()\n",
    "\n",
    "  serve = serve_op()\n",
    "  serve.after(train)\n",
    "\n",
    "  resultsgen = resultsgen_op()\n",
    "  resultsgen.after(serve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit an experiment *run*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(trackml, 'trackml.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call below will run the compiled pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.run_pipeline(exp.id, 'trackml', 'trackml.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
